{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "# for plotting\n",
    "import seaborn as sns\n",
    "sns.set(style='white', font_scale=1.5)\n",
    "#for working with Bam files\n",
    "import pysam\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "#for distance\n",
    "from scipy.spatial import distance\n",
    "import datetime\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import logging\n",
    "from gridmap import grid_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/broad/mushroom_lasagna/YB/Ht115_lineage_on_itself\n"
     ]
    }
   ],
   "source": [
    "cd /broad/mushroom_lasagna/YB/Ht115_lineage_on_itself/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T34_N48.txt\n"
     ]
    }
   ],
   "source": [
    "################################################################\n",
    "#create the header file _ by using the original output file\n",
    "frames=[]\n",
    "out_files = !ls | grep 'T'\n",
    "f=out_files[3]\n",
    "print f\n",
    "!grep contig {f} > /broad/mushroom_lasagna/YB/{'header2.txt'} \n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t76419\tTAAxGCC\tT\tG\tT34\tN48\t0\tNOVEL\tCOVERED\t0.954491\t0.954491\t1\t1\t0.999912\t141\t55\t0.303488\t7.938785\t-0.240667\t9.165872\t0.104167\t0.02\t-0.420221\t47\t43\t5\t1236\t124\t40\t37\t0\t0\tTT\t15.847652\t0.015625\t32\t63\t1\t1743\t29\t0.794929\t0.88241\t(27,16,1,4)\t20\t10\t129\t11\t0\t\tKEEP\r\n",
      "1\t99014\tATTxATT\tT\tC\tT34\tN48\t0\tNOVEL\tCOVERED\t1\t1\t1\t1\t1\t249\t2\t-17.123764\t9.758706\t4.941053\t4.84515\t0.048387\t0.02\t2.682436\t131\t118\t6\t3311\t173\t60\t45\t2\t0\tTT\t29.601009\t0.009091\t107\t109\t1\t3055\t30\t0.876241\t0.784668\t(50,68,3,3)\t117.5\t4.5\t28\t0.5\t0\t\tKEEP\r\n",
      "1\t1131218\tTCTxCCT\tC\tT\tT34\tN48\t0\tNOVEL\tCOVERED\t0.941741\t0.941741\t1\t1\t0.999974\t85\t0\t0.283412\t7.952986\t1.656884\t6.468233\t0.088889\t0.02\t-0.411888\t46\t41\t4\t1188\t119\t60\t60\t0\t0\tCC\t11.367335\t0\t36\t38\t0\t1058\t0\t0.774405\t0.798238\t(22,19,1,3)\t58.5\t12\t91.5\t12\t0\t\tKEEP\r\n",
      "1\t1137744\tCCCxAGC\tG\tC\tT34\tN48\t0\tNOVEL\tUNCOVERED\t0.138793\t0.139832\t0.99257\t0.99257\t0\t35\t15\t6.842018\t6.871529\t1.080468\t6.134259\t0.444444\t0.02\t-0.094677\t9\t5\t4\t125\t77\t31\t32\t0\t0\tGG\t4.465581\t0.052632\t6\t18\t1\t419\t8\t0.983402\t0.62965\t(0,5,1,3)\t112\t24.5\t35.5\t23\t0\t\tKEEP\r\n",
      "1\t1138138\tCCAxCCC\tT\tG\tT34\tN48\t0\tNOVEL\tCOVERED\t0.851444\t0.851984\t0.999366\t0.999366\t0\t57\t2\t3.129646\t6.635259\t3.832749\t4.582904\t0.181818\t0.02\t-0.302964\t25\t27\t6\t672\t104\t60\t60\t0\t0\tTT\t2.278365\t0.166667\t8\t15\t3\t329\t19\t0.812356\t0.980298\t(23,4,2,4)\t31\t18.5\t103.5\t8.5\t0\t\tKEEP\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 T34_N48.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('for: ', 'T34_N37.txt', ' -The size is: ', (13222, 51))\n",
      "('for: ', 'T34_N45.txt', ' -The size is: ', (5023, 51))\n",
      "('for: ', 'T34_N47.txt', ' -The size is: ', (5093, 51))\n",
      "('for: ', 'T34_N48.txt', ' -The size is: ', (4812, 51))\n",
      "('for: ', 'T34_N49.txt', ' -The size is: ', (5029, 51))\n",
      "('for: ', 'T34_N54.txt', ' -The size is: ', (5193, 51))\n",
      "('for: ', 'T34_N63.txt', ' -The size is: ', (5130, 51))\n",
      "('for: ', 'T37_N34.txt', ' -The size is: ', (36750, 51))\n",
      "('for: ', 'T37_N45.txt', ' -The size is: ', (36775, 51))\n",
      "('for: ', 'T37_N47.txt', ' -The size is: ', (36811, 51))\n",
      "('for: ', 'T37_N48.txt', ' -The size is: ', (36801, 51))\n",
      "('for: ', 'T37_N49.txt', ' -The size is: ', (37411, 51))\n",
      "('for: ', 'T37_N54.txt', ' -The size is: ', (36701, 51))\n",
      "('for: ', 'T37_N63.txt', ' -The size is: ', (37363, 51))\n",
      "('for: ', 'T45_N34.txt', ' -The size is: ', (3078, 51))\n",
      "('for: ', 'T45_N37.txt', ' -The size is: ', (11439, 51))\n",
      "('for: ', 'T45_N47.txt', ' -The size is: ', (3414, 51))\n",
      "('for: ', 'T45_N48.txt', ' -The size is: ', (2539, 51))\n",
      "('for: ', 'T45_N49.txt', ' -The size is: ', (3852, 51))\n",
      "('for: ', 'T45_N54.txt', ' -The size is: ', (3494, 51))\n",
      "('for: ', 'T45_N63.txt', ' -The size is: ', (3985, 51))\n",
      "('for: ', 'T47_N34.txt', ' -The size is: ', (3472, 51))\n",
      "('for: ', 'T47_N37.txt', ' -The size is: ', (11989, 51))\n",
      "('for: ', 'T47_N45.txt', ' -The size is: ', (3835, 51))\n",
      "('for: ', 'T47_N48.txt', ' -The size is: ', (3612, 51))\n",
      "('for: ', 'T47_N49.txt', ' -The size is: ', (4192, 51))\n",
      "('for: ', 'T47_N54.txt', ' -The size is: ', (2940, 51))\n",
      "('for: ', 'T47_N63.txt', ' -The size is: ', (4325, 51))\n",
      "('for: ', 'T48_N34.txt', ' -The size is: ', (3622, 51))\n",
      "('for: ', 'T48_N37.txt', ' -The size is: ', (12082, 51))\n",
      "('for: ', 'T48_N45.txt', ' -The size is: ', (3377, 51))\n",
      "('for: ', 'T48_N47.txt', ' -The size is: ', (3973, 51))\n",
      "('for: ', 'T48_N49.txt', ' -The size is: ', (4423, 51))\n",
      "('for: ', 'T48_N54.txt', ' -The size is: ', (4137, 51))\n",
      "('for: ', 'T48_N63.txt', ' -The size is: ', (4598, 51))\n",
      "('for: ', 'T49_N34.txt', ' -The size is: ', (3848, 51))\n",
      "('for: ', 'T49_N37.txt', ' -The size is: ', (12862, 51))\n",
      "('for: ', 'T49_N45.txt', ' -The size is: ', (4592, 51))\n",
      "('for: ', 'T49_N47.txt', ' -The size is: ', (4611, 51))\n",
      "('for: ', 'T49_N48.txt', ' -The size is: ', (4456, 51))\n",
      "('for: ', 'T49_N54.txt', ' -The size is: ', (4794, 51))\n",
      "('for: ', 'T49_N63.txt', ' -The size is: ', (3880, 51))\n",
      "('for: ', 'T54_N34.txt', ' -The size is: ', (3169, 51))\n",
      "('for: ', 'T54_N37.txt', ' -The size is: ', (11585, 51))\n",
      "('for: ', 'T54_N45.txt', ' -The size is: ', (3469, 51))\n",
      "('for: ', 'T54_N47.txt', ' -The size is: ', (2536, 51))\n",
      "('for: ', 'T54_N48.txt', ' -The size is: ', (3314, 51))\n",
      "('for: ', 'T54_N49.txt', ' -The size is: ', (3939, 51))\n",
      "('for: ', 'T54_N63.txt', ' -The size is: ', (4002, 51))\n",
      "('for: ', 'T63_N34.txt', ' -The size is: ', (2824, 51))\n",
      "('for: ', 'T63_N37.txt', ' -The size is: ', (11777, 51))\n",
      "('for: ', 'T63_N45.txt', ' -The size is: ', (3569, 51))\n",
      "('for: ', 'T63_N47.txt', ' -The size is: ', (3500, 51))\n",
      "('for: ', 'T63_N48.txt', ' -The size is: ', (3396, 51))\n",
      "('for: ', 'T63_N49.txt', ' -The size is: ', (2788, 51))\n",
      "('for: ', 'T63_N54.txt', ' -The size is: ', (3686, 51))\n",
      "(507089, 51)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/broad/software/free/Linux/redhat_6_x86_64/pkgs/anaconda_2.1.0/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2871: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#load all files into one big table - sort by \n",
    "frames=[]\n",
    "out_files = !ls | grep 'T'\n",
    "count=1\n",
    "columns = pd.read_csv('/broad/mushroom_lasagna/YB/header.txt', sep='\\t', comment='#').columns\n",
    "for file in out_files:\n",
    "    wt = pd.read_csv(file, sep='\\t')\n",
    "    wt = pd.DataFrame(wt.as_matrix(), columns=columns)\n",
    "    print (\"for: \",file,\" -The size is: \",wt.shape)\n",
    "    if (count==1):\n",
    "        wf=wt\n",
    "    else:\n",
    "        wf=wf.append(wt, ignore_index=True)\n",
    "    count=count+1\n",
    "print (wf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd /seq/picard_aggregation/G101103/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cwf=wf.drop_duplicates(['position','contig'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f1=open('/broad/mushroom_lasagna/YB/Ht115_lineage_on_itself/log.txt', 'w+')\n",
    "co=1\n",
    "columns=('contig','position','context','ref_all','alt_all','t_lod_fstar','vector','distance_in_g1','distance_in_g2','per_bet_gr','real_bet_gr','ref_af','alt_af','type','full_data')\n",
    "mutation=[]\n",
    "f1.write(\"Log for run: /n\")\n",
    "keep=['contig', 'position','context', 'ref_allele','alt_allele','t_lod_fstar']\n",
    "locations=cwf[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This section get table with locations and for each location add the spot in all the samples\n",
    "#and save the table - should run only once.\n",
    "#def mat_from_bam(locations):\n",
    "# this have to be in seperate line - ??????\n",
    "#!cd /seq/picard_aggregation/G101103/\n",
    "f1=open('/broad/mushroom_lasagna/YB/Ht115_lineage_on_itself/log.txt', 'w+')\n",
    "f1.write(\"Log for run: /n\")\n",
    "\n",
    "head=[]\n",
    "begin=!pwd \n",
    "begin=begin.pop()\n",
    "out_files = !ls | grep HT6\n",
    "    #prepare list of all bam files to read\n",
    "    #open bam file and load all the locations - and add to the table\n",
    "for f in out_files:\n",
    "    path=\"%s/%s/v4/%s.bam\"%(begin,f,f)\n",
    "    head.append(f)\n",
    "    samfile = pysam.AlignmentFile(path, \"rb\")\n",
    "        #Samples.append(samfile)\n",
    "        #for every bam file run over all the mutations\n",
    "    seq=[]\n",
    "    f1.write(\"Reading from file: %s\\n\"%(f))\n",
    "    f1.flush()\n",
    "    for i in locations.index:\n",
    "        if (i%500 ==0):\n",
    "            f1.write(\"file %s finished = %i lines\\n\" %(f,i))\n",
    "            f1.flush()\n",
    "        s=\"\"\n",
    "        chr= str(locations.contig[i])\n",
    "        region= int(float(locations.position[i]))\n",
    "        region=region-1\n",
    "        for row in samfile.pileup(chr,region,region+1):\n",
    "                if row.pos ==region:\n",
    "                    for row in row.pileups:\n",
    "                        if (row.query_position is not None):\n",
    "                            #print (row.query_position)\n",
    "                            #print (row.alignment.query_sequence[row.query_position])\n",
    "                            s+=row.alignment.query_sequence[row.query_position]\n",
    "        s=''.join(sorted(s.upper()))\n",
    "        seq.append(s)\n",
    "        # add the seq as column in the db - location\n",
    "    #locations[f]=pd.Series(seq,index=f)\n",
    "    #print \"f= \",f,\" len seq= \",seq\n",
    "    locations[f]=seq\n",
    "\n",
    "########################\n",
    "#and save the new table\n",
    "locations.to_pickle('/broad/mushroom_lasagna/YB/Ht115_lineage_on_itself/mutations.pkl')\n",
    "f1.write(\"file %s finished = %i lines\\n\" %(f,i))\n",
    "f1.flush()\n",
    "close(f1)\n",
    "f1.write(\"finito\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
